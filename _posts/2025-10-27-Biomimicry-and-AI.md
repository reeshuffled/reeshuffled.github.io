---
layout: post
type: notes
tags:
- Artificial Intelligence
title: Biomimicry and AI
slug: biomimicry-and-ai
description: My notes on Dwarkesh Patel's interview of Andrej Karpathy.
started_at: '2025-10-23 18:02:00'
---

[Andrej Karpathy — “We’re summoning ghosts, not building animals” \| Dwarkesh Patel on YouTube](https://www.youtube.com/watch?v=lXUZvyajciY)  
[Animals vs Ghosts \| Andrej Karpathy on his blog](https://karpathy.bearblog.dev/animals-vs-ghosts/)

Evolution and structure of the brain gives us a lot of animal intelligence rather than RL (probably)

Sutton seems to want to create an animal or bio-mimicked version of AI which may or may not be possible
* Surely it seems possible but maybe only as an emergent property of our biology? which would mean we would need to fully model a brain to really get anywhere which doesn’t seem very easy

LLMs have knowledge and probably some kind of reasoning but over reliant on knowledge which is bad and we can maybe distill it to a "cognitive core"

LLM context window is like working memory? ish — analogy is only accidental probably

Is LLM attention really like human attention?

Transformer as Cortical Tissue?

What parts of the brain aren’t strictly necessary for cognition and can we skip them? Should we be trying to recreate humans?
* It makes sense to try to chase humans a bit since that is the kind of intelligence we are generally looking for.
    * Will they be limited by human limits? Are there structural limits?

LLMs don’t sleep/dream and so there isn’t any synthetic data generation or distillation and backpropagation of weights
* how can we get this to work without model collapse? — maybe this isn’t possible because maybe humans collapse too

We may converge to similar architecture (LLMs and brains)

All fronts have to improve for LLMs to improve (hardware, software, data, etc.)

Reflect and Review meta learning could be useful